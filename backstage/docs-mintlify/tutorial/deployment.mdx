---
title: Deployment
description: Deploy your Vertz app to production
---

# Step 7: Deployment

Let's deploy our chatbot to production.

## Build for Production

```bash
npm run build
```

This creates optimized production builds for both client and server.

## Deployment Options

### Option 1: Vercel (Recommended)

```bash
npm install -g vercel
vercel
```

Configure `vercel.json`:

```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "dist",
  "framework": "vertz"
}
```

### Option 2: Docker

Create `Dockerfile`:

```dockerfile
FROM oven/bun:1 AS base
WORKDIR /app

# Install dependencies
FROM base AS install
COPY package.json bun.lockb ./
RUN bun install --frozen-lockfile

# Build
FROM base AS build
COPY --from=install /app/node_modules /app/node_modules
COPY . .
RUN bun run build

# Run
FROM base
COPY --from=build /app/dist /app/dist
COPY --from=build /app/node_modules /app/node_modules

ENV NODE_ENV=production
EXPOSE 3000

CMD ["bun", "run", "src/server/index.ts"]
```

Build and run:

```bash
docker build -t chatbot .
docker run -p 3000:3000 chatbot
```

### Option 3: Node.js Server

```bash
# Build
npm run build

# Start server
NODE_ENV=production bun run src/server/index.ts
```

## Environment Variables

Set production environment variables:

```bash
# Database
DATABASE_URL="postgresql://user:pass@host:5432/chatbot"

# Auth
AUTH_SECRET="production-secret-key"

# LLM
OPENAI_API_KEY="sk-prod-..."
```

## Database Migration

Run migrations on production:

```bash
npx vertx db migrate --env production
```

## Monitoring

Add error tracking:

```bash
npm install @vertz/monitoring
```

Configure in `src/server/index.ts`:

```typescript
import { vertz } from '@vertz/server';
import { monitoring } from '@vertz/monitoring';

const app = vertz({
  plugins: [
    monitoring({
      serviceName: 'chatbot',
      dsn: process.env.SENTRY_DSN,
    }),
  ],
  // ... rest of config
});
```

## Performance Tips

1. **Enable caching** â€” Use `@vertz/cache` for frequent queries
2. **Stream responses** â€” Use `streamingProcedure` for LLM responses
3. **Database connections** â€” Use connection pooling for production
4. **CDN** â€” Serve static assets from a CDN

## Congratulations! ðŸŽ‰

You've built a complete LLM-powered chatbot with:

- Type-safe React UI
- Database with entities
- User authentication
- LLM integration
- Production deployment

## Next Steps

- Explore the [API Reference](/api-reference)
- Join our [Discord](https://discord.gg/vertz)
- Star us on [GitHub](https://github.com/vertz-dev/vertz)
